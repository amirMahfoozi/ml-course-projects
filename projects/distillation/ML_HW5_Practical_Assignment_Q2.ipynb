{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VivaFsd3Q6cj"
      },
      "source": [
        "<br>\n",
        "<font>\n",
        "<div dir=ltr align=center>\n",
        "<img src=\"https://cdn.freebiesupply.com/logos/large/2x/sharif-logo-png-transparent.png\" width=150 height=150> <br>\n",
        "<font color=0F5298 size=7>\n",
        "    Machine learning <br>\n",
        "<font color=2565AE size=5>\n",
        "    Computer Engineering Department <br>\n",
        "    Fall 2024<br>\n",
        "<font color=3C99D size=5>\n",
        "    Practical Assignment 5 - NLP - Transformer & Bert <br>\n",
        "</div>\n",
        "<div dir=ltr align=center>\n",
        "<font color=0CBCDF size=4>\n",
        "   &#x1F349; Masoud Tahmasbi  &#x1F349;  &#x1F353; Arash Ziyaei &#x1F353;\n",
        "<br>\n",
        "<font color=0CBCDF size=4>\n",
        "   &#x1F335; Amirhossein Akbari  &#x1F335;\n",
        "</div>\n",
        "\n",
        "____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k15QziPnmC6d"
      },
      "source": [
        "<font color=9999FF size=4>\n",
        "&#x1F388; Full Name : Amir Mohammad Mahfoozi\n",
        "<br>\n",
        "<font color=9999FF size=4>\n",
        "&#x1F388; Student Number : 401106469"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOfpEN2xmbN8"
      },
      "source": [
        "<font color=0080FF size=3>\n",
        "This notebook covers two key topics. First, we implement a transformer model from scratch and apply it to a specific task. Second, we fine-tune the BERT model using LoRA for efficient adaptation to a downstream task.\n",
        "</font>\n",
        "<br>\n",
        "\n",
        "**Note:**\n",
        "<br>\n",
        "<font color=66B2FF size=2>In this notebook, you are free to use any function or model from PyTorch to assist with the implementation. However, TensorFlow is not permitted for this exercise. This ensures consistency and alignment with the tools being focused on.</font>\n",
        "<br>\n",
        "<font color=red size=3>**Run All Cells Before Submission**</font>: <font color=FF99CC size=2>Before saving and submitting your notebook, please ensure you run all cells from start to finish. This practice guarantees that your notebook is self-consistent and can be evaluated correctly by others.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpvvM0995ieR"
      },
      "source": [
        "# Section 1: Transformer\n",
        "\n",
        "The transformer architecture consists of two main components: an encoder and a decoder. Each of these components is made up of multiple layers that include self-attention mechanisms and feedforward neural networks. The self-attention mechanism is central to the transformer, as it enables the model to assess the importance of different words in a sentence by considering their relationships with one another.\n",
        "\n",
        "\n",
        "In this assignment, you should design a transformer model from scratch. You are required to implement the Encoder and Decoder components of a Transformer model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzIob6-Gq7Lw",
        "outputId": "4e0e7734-9394-4f6f-e8b7-36cbe3ae59d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# Importing libraries\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Math\n",
        "import math\n",
        "\n",
        "# HuggingFace libraries\n",
        "!pip install datasets\n",
        "\n",
        "from datasets import load_dataset\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "\n",
        "# Pathlib\n",
        "from pathlib import Path\n",
        "\n",
        "# typing\n",
        "from typing import Any\n",
        "\n",
        "# Library for progress bars in loops\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Importing library of warnings\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-71SfIAJprox"
      },
      "source": [
        "## Part 1: Input Embeddings\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">When we observe the Transformer architecture image above, we can see that the Embeddings represent the first step of both blocks.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The <code>InputEmbedding</code> class below is responsible for converting the input text into numerical vectors of <code>d_model</code> dimensions. To prevent that our input embeddings become extremely small, we normalize them by multiplying them by the $\\sqrt{d_{model}}$.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the image below, we can see how the embeddings are created. First, we have a sentence that gets split into tokens—we will explore what tokens are later on—. Then, the token IDs—identification numbers—are transformed into the embeddings, which are high-dimensional vectors.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-pyrJlu4Nl7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class TokenEmbeddings(nn.Module):\n",
        "    def __init__(self, embedding_dim: int, vocab_size: int) -> None:\n",
        "        super().__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.token_vocab_size = vocab_size\n",
        "        self.embedding_layer = self._initialize_embedding()\n",
        "\n",
        "    def _initialize_embedding(self) -> nn.Embedding:\n",
        "        return nn.Embedding(self.token_vocab_size, self.embedding_dim)\n",
        "\n",
        "    def scale_embeddings(self, embeddings: torch.Tensor) -> torch.Tensor:\n",
        "        return embeddings * math.sqrt(self.embedding_dim)\n",
        "\n",
        "    def forward(self, input_indices: torch.Tensor) -> torch.Tensor:\n",
        "        embedded_tokens = self.embedding_layer(input_indices)\n",
        "        return self.scale_embeddings(embedded_tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWBlo2XorJGW"
      },
      "source": [
        "## Part 2: positional encoding\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the original paper, the authors add the positional encodings to the input embeddings at the bottom of both the encoder and decoder blocks so the model can have some information about the relative or absolute position of the tokens in the sequence. The positional encodings have the same dimension $d_{model}$ as the embeddings, so that the two vectors can be summed and we can combine the semantic content from the word embeddings and positional information from the positional encodings.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the <code>PositionalEncoding</code> class below, we will create a matrix of positional encodings <code>pe</code> with dimensions <code>(seq_len, d_model)</code>. We will start by filling it with $0$s.We will then apply the sine function to even indices of the positional encoding matrix while the cosine function is applied to the odd ones.</p>\n",
        "\n",
        "<p style=\"\n",
        "    margin-bottom: 5;\n",
        "    font-size: 22px;\n",
        "    font-weight: 300;\n",
        "    font-family: 'Helvetica Neue', sans-serif;\n",
        "    color: #000000;\n",
        "  \">\n",
        "    \\begin{equation}\n",
        "    \\text{Odd Indices } (2i + 1): \\quad \\text{PE(pos, } 2i + 1) = \\cos\\left(\\frac{\\text{pos}}{10000^{2i / d_{model}}}\\right)\n",
        "    \\end{equation}\n",
        "</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We apply the sine and cosine functions because it allows the model to determine the position of a word based on the position of other words in the sequence, since for any fixed offset $k$, $PE_{pos + k}$ can be represented as a linear function of $PE_{pos}$. This happens due to the properties of sine and cosine functions, where a shift in the input results in a predictable change in the output.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZG5DhVcrVVm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim: int, sequence_length: int, dropout_rate: float) -> None:\n",
        "        super().__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.sequence_length = sequence_length\n",
        "        self.dropout_layer = nn.Dropout(dropout_rate)\n",
        "        self.positional_matrix = self._generate_positional_encoding()\n",
        "        self.register_buffer('positional_encoding', self.positional_matrix)\n",
        "\n",
        "    def _generate_positional_encoding(self) -> torch.Tensor:\n",
        "        position_matrix = torch.zeros(self.sequence_length, self.embedding_dim)\n",
        "        position_indices = torch.arange(0, self.sequence_length, dtype=torch.float).unsqueeze(1)\n",
        "        frequency_term = torch.exp(torch.arange(0, self.embedding_dim, 2).float() * (-math.log(10000.0) / self.embedding_dim))\n",
        "        position_matrix[:, 0::2] = torch.sin(position_indices * frequency_term)\n",
        "        position_matrix[:, 1::2] = torch.cos(position_indices * frequency_term)\n",
        "        return position_matrix.unsqueeze(0)\n",
        "\n",
        "    def add_positional_encoding(self, input_tensor: torch.Tensor) -> torch.Tensor:\n",
        "        return input_tensor + self.positional_encoding[:, :input_tensor.shape[1], :].requires_grad_(False)\n",
        "\n",
        "    def forward(self, input_tensor: torch.Tensor) -> torch.Tensor:\n",
        "        input_with_encoding = self.add_positional_encoding(input_tensor)\n",
        "        return self.dropout_layer(input_with_encoding)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T92iydQErh-P"
      },
      "source": [
        "## Part 3: layer normalization\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">When we look at the encoder and decoder blocks, we see several normalization layers called <b><i>Add &amp; Norm</i></b>.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The <code>LayerNormalization</code> class below performs layer normalization on the input data. During its forward pass, we compute the mean and standard deviation of the input data. We then normalize the input data by subtracting the mean and dividing by the standard deviation plus a small number called epsilon to avoid any divisions by zero. This process results in a normalized output with a mean 0 and a standard deviation 1.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We will then scale the normalized output by a learnable parameter <code>alpha</code> and add a learnable parameter called <code>bias</code>. The training process is responsible for adjusting these parameters. The final result is a layer-normalized tensor, which ensures that the scale of the inputs to layers in the network is consistent.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVGQRsmKrwZu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LayerNormalization(nn.Module):\n",
        "\n",
        "    def __init__(self, num_features: int, epsilon: float = 1e-6) -> None:\n",
        "        super().__init__()\n",
        "        self.epsilon = epsilon\n",
        "        self.scale_factor = nn.Parameter(torch.ones(num_features))\n",
        "        self.offset = nn.Parameter(torch.zeros(num_features))\n",
        "\n",
        "    def compute_statistics(self, input_tensor: torch.Tensor) -> tuple:\n",
        "        mean = input_tensor.mean(dim=-1, keepdim=True)\n",
        "        std = input_tensor.std(dim=-1, keepdim=True)\n",
        "        return mean, std\n",
        "\n",
        "    def normalize(self, input_tensor: torch.Tensor, mean: torch.Tensor, std: torch.Tensor) -> torch.Tensor:\n",
        "        return (input_tensor - mean) / (std + self.epsilon)\n",
        "\n",
        "    def forward(self, input_tensor: torch.Tensor) -> torch.Tensor:\n",
        "        mean, std = self.compute_statistics(input_tensor)\n",
        "        normalized_tensor = self.normalize(input_tensor, mean, std)\n",
        "        return self.scale_factor * normalized_tensor + self.offset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-IbSGQMr1Ye"
      },
      "source": [
        "## Part 4: Feed Forward Network\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the fully connected feed-forward network, we apply two linear transformations with a ReLU activation in between. We can mathematically represent this operation as:</p>\n",
        "\n",
        "<p style=\"\n",
        "    margin-bottom: 5;\n",
        "    font-size: 22px;\n",
        "    font-weight: 300;\n",
        "    font-family: 'Helvetica Neue', sans-serif;\n",
        "    color: #000000;\n",
        "  \">\n",
        "    \\begin{equation}\n",
        "    \\text{FFN}(x) = \\max(0, xW_1 + b_1)W_2 + b_2\n",
        "    \\end{equation}\n",
        "</p>\n",
        "\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">$W_1$ and $W_2$ are the weights, while $b_1$ and $b_2$ are the biases of the two linear transformations.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the <code>FeedForwardBlock</code> below, we will define the two linear transformations—<code>self.linear_1</code> and <code>self.linear_2</code>—and the inner-layer <code>d_ff</code>. The input data will first pass through the <code>self.linear_1</code> transformation, which increases its dimensionality from <code>d_model</code> to <code>d_ff</code>. The output of this operation passes through the ReLU activation function, which introduces non-linearity so the network can learn more complex patterns, and the <code>self.dropout</code> layer is applied to mitigate overfitting. The final operation is the <code>self.linear_2</code> transformation to the dropout-modified tensor, which transforms it back to the original <code>d_model</code> dimension.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3H8kyccsEUW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class FeedForwardBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim: int, hidden_dim: int, dropout_rate: float) -> None:\n",
        "        super().__init__()\n",
        "        self.input_to_hidden = nn.Linear(input_dim, hidden_dim)\n",
        "        self.hidden_dropout = nn.Dropout(dropout_rate)\n",
        "        self.hidden_to_output = nn.Linear(hidden_dim, input_dim)\n",
        "\n",
        "    def apply_activation_and_dropout(self, hidden_tensor: torch.Tensor) -> torch.Tensor:\n",
        "        activated_tensor = torch.relu(hidden_tensor)\n",
        "        return self.hidden_dropout(activated_tensor)\n",
        "\n",
        "    def forward(self, input_tensor: torch.Tensor) -> torch.Tensor:\n",
        "        hidden_tensor = self.input_to_hidden(input_tensor)\n",
        "        activated_tensor = self.apply_activation_and_dropout(hidden_tensor)\n",
        "        return self.hidden_to_output(activated_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEa1kF6csIvV"
      },
      "source": [
        "## Part 5: Multi Head Attention\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The Multi-Head Attention is the most crucial component of the Transformer. It is responsible for helping the model to understand complex relationships and patterns in the data.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The image below displays how the Multi-Head Attention works. It doesn't include <code>batch</code> dimension because it only illustrates the process for one single sentence.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The Multi-Head Attention block receives the input data split into queries, keys, and values organized into matrices $Q$, $K$, and $V$. Each matrix contains different facets of the input, and they have the same dimensions as the input.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We then linearly transform each matrix by their respective weight matrices $W^Q$, $W^K$, and $W^V$. These transformations will result in new matrices $Q'$, $K'$, and $V'$, which will be split into smaller matrices corresponding to different heads $h$, allowing the model to attend to information from different representation subspaces in parallel. This split creates multiple sets of queries, keys, and values for each head.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">Finally, we concatenate every head into an $H$ matrix, which is then transformed by another weight matrix $W^o$ to produce the multi-head attention output, a matrix $MH-A$ that retains the input dimensionality.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ujcqPp1sOU9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class MultiHeadAttentionBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, model_dim: int, num_heads: int, dropout_rate: float) -> None:\n",
        "        super().__init__()\n",
        "        self.model_dim = model_dim\n",
        "        self.num_heads = num_heads\n",
        "        assert model_dim % num_heads == 0, \"model_dim must be divisible by num_heads\"\n",
        "\n",
        "        self.head_dim = model_dim // num_heads\n",
        "        self.query_weight = nn.Linear(model_dim, model_dim, bias=False)\n",
        "        self.key_weight = nn.Linear(model_dim, model_dim, bias=False)\n",
        "        self.value_weight = nn.Linear(model_dim, model_dim, bias=False)\n",
        "        self.output_weight = nn.Linear(model_dim, model_dim, bias=False)\n",
        "        self.dropout_layer = nn.Dropout(dropout_rate)\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_attention_scores(query_tensor, key_tensor, value_tensor, mask_tensor, dropout_layer):\n",
        "        scaling_factor = query_tensor.shape[-1] ** 0.5\n",
        "        scores = query_tensor @ key_tensor.transpose(-2, -1) / scaling_factor\n",
        "        if mask_tensor is not None:\n",
        "            scores.masked_fill_(mask_tensor == 0, -1e9)\n",
        "        scores = scores.softmax(dim=-1)\n",
        "        if dropout_layer is not None:\n",
        "            scores = dropout_layer(scores)\n",
        "        return scores @ value_tensor, scores\n",
        "\n",
        "    def reshape_for_heads(self, tensor):\n",
        "        batch_size, seq_length, _ = tensor.shape\n",
        "        return tensor.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "    def combine_heads(self, tensor):\n",
        "        batch_size, num_heads, seq_length, head_dim = tensor.shape\n",
        "        return tensor.transpose(1, 2).contiguous().view(batch_size, seq_length, num_heads * head_dim)\n",
        "\n",
        "    def forward(self, query_input, key_input, value_input, mask_tensor):\n",
        "        query_tensor = self.reshape_for_heads(self.query_weight(query_input))\n",
        "        key_tensor = self.reshape_for_heads(self.key_weight(key_input))\n",
        "        value_tensor = self.reshape_for_heads(self.value_weight(value_input))\n",
        "\n",
        "        attention_output, self.attention_scores = self.compute_attention_scores(\n",
        "            query_tensor, key_tensor, value_tensor, mask_tensor, self.dropout_layer\n",
        "        )\n",
        "\n",
        "        combined_output = self.combine_heads(attention_output)\n",
        "        return self.output_weight(combined_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCaLjCVxsWIc"
      },
      "source": [
        "## Part 6: Residual Connection\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">When we look at the architecture of the Transformer, we see that each sub-layer, including the <i>self-attention</i> and <i>Feed Forward</i> blocks, adds its output to its input before passing it to the <i>Add &amp; Norm</i> layer. This approach integrates the output with the original input in the <i>Add &amp; Norm</i> layer. This process is known as the skip connection, which allows the Transformer to train deep networks more effectively by providing a shortcut for the gradient to flow through during backpropagation.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The <code>ResidualConnection</code> class below is responsible for this process.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-bvuGhIsdfu"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class ResidualConnection(nn.Module):\n",
        "    def __init__(self, input_size: int, dropout_rate: float) -> None:\n",
        "        super().__init__()\n",
        "        self.dropout_layer = nn.Dropout(dropout_rate)\n",
        "        self.layer_norm = LayerNormalization(input_size)\n",
        "\n",
        "    def forward(self, input_tensor, sublayer_fn):\n",
        "        normed_tensor = self._normalize_input(input_tensor)\n",
        "        sublayer_output = self._apply_sublayer(normed_tensor, sublayer_fn)\n",
        "        return self._apply_residual_connection(input_tensor, sublayer_output)\n",
        "\n",
        "    def _normalize_input(self, input_tensor):\n",
        "        return self.layer_norm(input_tensor)\n",
        "\n",
        "    def _apply_sublayer(self, normed_tensor, sublayer_fn):\n",
        "        return sublayer_fn(normed_tensor)\n",
        "\n",
        "    def _apply_residual_connection(self, original_input, sublayer_output):\n",
        "        return original_input + self.dropout_layer(sublayer_output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YYI5vpasdGm"
      },
      "source": [
        "## Part 7: Encoder\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We will now build the encoder. We create the <code>EncoderBlock</code> class, consisting of the Multi-Head Attention and Feed Forward layers, plus the residual connections.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the original paper, the Encoder Block repeats six times. We create the <code>Encoder</code> class as an assembly of multiple <code>EncoderBlock</code>s. We also add layer normalization as a final step after processing the input through all its blocks.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRtppwE1s0-t"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, input_size: int, self_attention: MultiHeadAttentionBlock, feed_forward: FeedForwardBlock, dropout_rate: float) -> None:\n",
        "        super().__init__()\n",
        "        self.self_attention_block = self_attention\n",
        "        self.feed_forward_block = feed_forward\n",
        "        self.residual_connections = nn.ModuleList([ResidualConnection(input_size, dropout_rate) for _ in range(2)])\n",
        "\n",
        "    def forward(self, input_tensor, source_mask):\n",
        "        attention_output = self._apply_self_attention(input_tensor, source_mask)\n",
        "        feed_forward_output = self._apply_feed_forward(attention_output)\n",
        "        return feed_forward_output\n",
        "\n",
        "    def _apply_self_attention(self, input_tensor, source_mask):\n",
        "        return self.residual_connections[0](input_tensor, lambda x: self.self_attention_block(x, x, x, source_mask))\n",
        "\n",
        "    def _apply_feed_forward(self, input_tensor):\n",
        "        return self.residual_connections[1](input_tensor, self.feed_forward_block)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSq7BZWcs5s1"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size: int, encoder_layers: nn.ModuleList) -> None:\n",
        "        super().__init__()\n",
        "        self.encoder_layers = encoder_layers\n",
        "        self.output_norm = LayerNormalization(input_size)\n",
        "\n",
        "    def forward(self, input_tensor, mask):\n",
        "        output_tensor = self._apply_layers(input_tensor, mask)\n",
        "        return self._normalize_output(output_tensor)\n",
        "\n",
        "    def _apply_layers(self, input_tensor, mask):\n",
        "        for layer in self.encoder_layers:\n",
        "            input_tensor = layer(input_tensor, mask)\n",
        "        return input_tensor\n",
        "\n",
        "    def _normalize_output(self, output_tensor):\n",
        "        return self.output_norm(output_tensor)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0HXE1fH5g0W"
      },
      "source": [
        "## Part 8: Decoder\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">Similarly, the Decoder also consists of several DecoderBlocks that repeat six times in the original paper. The main difference is that it has an additional sub-layer that performs multi-head attention with a <i>cross-attention</i> component that uses the output of the Encoder as its keys and values while using the Decoder's input as queries.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">For the Output Embedding, we can use the same <code>InputEmbeddings</code> class we use for the Encoder. You can also notice that the self-attention sub-layer is <i>masked</i>, which restricts the model from accessing future elements in the sequence.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We will start by building the <code>DecoderBlock</code> class, and then we will build the <code>Decoder</code> class, which will assemble multiple <code>DecoderBlock</code>s.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9Aof9mb4PJX"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, input_size: int, self_attention: MultiHeadAttentionBlock, cross_attention: MultiHeadAttentionBlock, feed_forward: FeedForwardBlock, dropout_rate: float) -> None:\n",
        "        super().__init__()\n",
        "        self.self_attention_block = self_attention\n",
        "        self.cross_attention_block = cross_attention\n",
        "        self.feed_forward_block = feed_forward\n",
        "        self.residual_connections = nn.ModuleList([ResidualConnection(input_size, dropout_rate) for _ in range(3)])\n",
        "\n",
        "    def forward(self, input_tensor, encoder_output, source_mask, target_mask):\n",
        "        attention_output = self._apply_self_attention(input_tensor, target_mask)\n",
        "        cross_attention_output = self._apply_cross_attention(attention_output, encoder_output, source_mask)\n",
        "        feed_forward_output = self._apply_feed_forward(cross_attention_output)\n",
        "        return feed_forward_output\n",
        "\n",
        "    def _apply_self_attention(self, input_tensor, target_mask):\n",
        "        return self.residual_connections[0](input_tensor, lambda x: self.self_attention_block(x, x, x, target_mask))\n",
        "\n",
        "    def _apply_cross_attention(self, input_tensor, encoder_output, source_mask):\n",
        "        return self.residual_connections[1](input_tensor, lambda x: self.cross_attention_block(x, encoder_output, encoder_output, source_mask))\n",
        "\n",
        "    def _apply_feed_forward(self, input_tensor):\n",
        "        return self.residual_connections[2](input_tensor, self.feed_forward_block)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwdthvkrtNUM"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size: int, decoder_layers: nn.ModuleList) -> None:\n",
        "        super().__init__()\n",
        "        self.decoder_layers = decoder_layers\n",
        "        self.output_norm = LayerNormalization(input_size)\n",
        "\n",
        "    def forward(self, input_tensor, encoder_output, source_mask, target_mask):\n",
        "        decoded_tensor = self._apply_decoder_layers(input_tensor, encoder_output, source_mask, target_mask)\n",
        "        return self._normalize_output(decoded_tensor)\n",
        "\n",
        "    def _apply_decoder_layers(self, input_tensor, encoder_output, source_mask, target_mask):\n",
        "        for layer in self.decoder_layers:\n",
        "            input_tensor = layer(input_tensor, encoder_output, source_mask, target_mask)\n",
        "        return input_tensor\n",
        "\n",
        "    def _normalize_output(self, decoded_tensor):\n",
        "        return self.output_norm(decoded_tensor)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qm4g_8O1tS3d"
      },
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">You can see in the Decoder image that after running a stack of <code>DecoderBlock</code>s, we have a Linear Layer and a Softmax function to the output of probabilities. The <code>ProjectionLayer</code> class below is responsible for converting the output of the model into a probability distribution over the <i>vocabulary</i>, where we select each output token from a vocabulary of possible tokens.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbWVoNintThN"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class ProjectionLayer(nn.Module):\n",
        "    def __init__(self, model_dim: int, vocab_size: int) -> None:\n",
        "        super().__init__()\n",
        "        self.linear_projection = nn.Linear(model_dim, vocab_size)\n",
        "\n",
        "    def forward(self, input_tensor) -> None:\n",
        "        projected_tensor = self._project_input(input_tensor)\n",
        "        log_probabilities = self._apply_log_softmax(projected_tensor)\n",
        "        return log_probabilities\n",
        "\n",
        "    def _project_input(self, input_tensor):\n",
        "        return self.linear_projection(input_tensor)\n",
        "\n",
        "    def _apply_log_softmax(self, projected_tensor):\n",
        "        return nn.functional.log_softmax(projected_tensor, dim=-1)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waCzPEAxtaR8"
      },
      "source": [
        "## Part 9: Building the Transformer\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We finally have every component of the Transformer architecture ready. We may now construct the Transformer by putting it all together.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the <code>Transformer</code> class below, we will bring together all the components of the model's architecture.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXbPW4oCtk2G"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, encoder: Encoder, decoder: Decoder, src_embed: InputEmbeddings, tgt_embed: InputEmbeddings, src_pos: PositionalEncoding, tgt_pos: PositionalEncoding, projection_layer: ProjectionLayer) -> None:\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = src_embed\n",
        "        self.tgt_embed = tgt_embed\n",
        "        self.src_pos = src_pos\n",
        "        self.tgt_pos = tgt_pos\n",
        "        self.projection_layer = projection_layer\n",
        "\n",
        "    def encode(self, src_input, src_mask):\n",
        "        embedded_src = self._apply_source_embedding(src_input)\n",
        "        positionally_encoded_src = self._apply_source_positional_encoding(embedded_src)\n",
        "        return self.encoder(positionally_encoded_src, src_mask)\n",
        "\n",
        "    def decode(self, encoder_output, src_mask, tgt_input, tgt_mask):\n",
        "        embedded_tgt = self._apply_target_embedding(tgt_input)\n",
        "        positionally_encoded_tgt = self._apply_target_positional_encoding(embedded_tgt)\n",
        "        return self.decoder(positionally_encoded_tgt, encoder_output, src_mask, tgt_mask)\n",
        "\n",
        "    def project(self, decoder_output):\n",
        "        return self.projection_layer(decoder_output)\n",
        "\n",
        "    def _apply_source_embedding(self, src_input):\n",
        "        return self.src_embed(src_input)\n",
        "\n",
        "    def _apply_target_embedding(self, tgt_input):\n",
        "        return self.tgt_embed(tgt_input)\n",
        "\n",
        "    def _apply_source_positional_encoding(self, embedded_src):\n",
        "        return self.src_pos(embedded_src)\n",
        "\n",
        "    def _apply_target_positional_encoding(self, embedded_tgt):\n",
        "        return self.tgt_pos(embedded_tgt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6znypMaetmRk"
      },
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The architecture is finally ready. We now define a function called <code>build_transformer</code>, in which we define the parameters and everything we need to have a fully operational Transformer model for the task of <b>machine translation</b>.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We will set the same parameters as in the original paper, <a href = \"https://arxiv.org/pdf/1706.03762.pdf\"><i>Attention Is All You Need</i></a>, where $d_{model}$ = 512, $N$ = 6, $h$ = 8, dropout rate $P_{drop}$ = 0.1, and $d_{ff}$ = 2048.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqGnJ6w2twJc"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "def build_transformer(src_vocab_size: int, tgt_vocab_size: int, src_seq_len: int, tgt_seq_len: int, d_model: int=512, N: int=6, h: int=8, dropout: float=0.1, d_ff: int=2048) -> Transformer:\n",
        "    src_embed = self._create_embedding_layer(d_model, src_vocab_size)\n",
        "    tgt_embed = self._create_embedding_layer(d_model, tgt_vocab_size)\n",
        "\n",
        "    src_pos = self._create_positional_encoding_layer(d_model, src_seq_len, dropout)\n",
        "    tgt_pos = self._create_positional_encoding_layer(d_model, tgt_seq_len, dropout)\n",
        "\n",
        "    encoder_blocks = self._create_encoder_blocks(d_model, h, N, dropout, d_ff)\n",
        "    decoder_blocks = self._create_decoder_blocks(d_model, h, N, dropout, d_ff)\n",
        "\n",
        "    encoder = Encoder(d_model, nn.ModuleList(encoder_blocks))\n",
        "    decoder = Decoder(d_model, nn.ModuleList(decoder_blocks))\n",
        "\n",
        "    projection_layer = ProjectionLayer(d_model, tgt_vocab_size)\n",
        "\n",
        "    transformer = Transformer(encoder, decoder, src_embed, tgt_embed, src_pos, tgt_pos, projection_layer)\n",
        "\n",
        "    self._initialize_parameters(transformer)\n",
        "\n",
        "    return transformer\n",
        "\n",
        "def _create_embedding_layer(self, d_model: int, vocab_size: int) -> InputEmbeddings:\n",
        "    return InputEmbeddings(d_model, vocab_size)\n",
        "\n",
        "def _create_positional_encoding_layer(self, d_model: int, seq_len: int, dropout: float) -> PositionalEncoding:\n",
        "    return PositionalEncoding(d_model, seq_len, dropout)\n",
        "\n",
        "def _create_encoder_blocks(self, d_model: int, h: int, N: int, dropout: float, d_ff: int) -> list:\n",
        "    encoder_blocks = []\n",
        "    for _ in range(N):\n",
        "        self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n",
        "        feed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\n",
        "        encoder_block = EncoderBlock(d_model, self_attention_block, feed_forward_block, dropout)\n",
        "        encoder_blocks.append(encoder_block)\n",
        "    return encoder_blocks\n",
        "\n",
        "def _create_decoder_blocks(self, d_model: int, h: int, N: int, dropout: float, d_ff: int) -> list:\n",
        "    decoder_blocks = []\n",
        "    for _ in range(N):\n",
        "        self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n",
        "        cross_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n",
        "        feed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\n",
        "        decoder_block = DecoderBlock(d_model, self_attention_block, cross_attention_block, feed_forward_block, dropout)\n",
        "        decoder_blocks.append(decoder_block)\n",
        "    return decoder_blocks\n",
        "\n",
        "def _initialize_parameters(self, transformer: Transformer) -> None:\n",
        "    for p in transformer.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw7CWf4bt3yr"
      },
      "source": [
        "The model is now ready to be trained!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_7Z3fEYuTK0"
      },
      "source": [
        "## Part 10: Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDinqTghqr_Q"
      },
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">Tokenization is a crucial preprocessing step for our Transformer model. In this step, we convert raw text into a number format that the model can process.  </p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">There are several Tokenization strategies. We will use the <i>word-level tokenization</i> to transform each word in a sentence into a token.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at-cYYjnqr_Q"
      },
      "source": [
        "<center>\n",
        "    <img src = \"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8d5e749c-b0bd-4496-85a1-9b4397ad935f_1400x787.jpeg\" width = 800, height= 800>\n",
        "<p style = \"font-size: 16px;\n",
        "            font-family: 'Georgia', serif;\n",
        "            text-align: center;\n",
        "            margin-top: 10px;\">Different tokenization strategies. Source: <a href = \"https://shaankhosla.substack.com/p/talking-tokenization\">shaankhosla.substack.com</a>.</p>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjRMr2N6qr_Q"
      },
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">After tokenizing a sentence, we map each token to an unique integer ID based on the created vocabulary present in the training corpus during the training of the tokenizer. Each integer number represents a specific word in the vocabulary.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">Besides the words in the training corpus, Transformers use special tokens for specific purposes. These are some that we will define right away:</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\"><b>• [UNK]:</b> This token is used to identify an unknown word in the sequence.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\"><b>• [PAD]:</b> Padding token to ensure that all sequences in a batch have the same length, so we pad shorter sentences with this token. We use attention masks to <i>\"tell\"</i> the model to ignore the padded tokens during training since they don't have any real meaning to the task.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\"><b>•  [SOS]:</b> This is a token used to signal the <i>Start of Sentence</i>.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\"><b>•  [EOS]:</b> This is a token used to signal the <i>End of Sentence</i>.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the <code>build_tokenizer</code> function below, we ensure a tokenizer is ready to train the model. It checks if there is an existing tokenizer, and if that is not the case, it trains a new tokenizer.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zh9pOItduxHq"
      },
      "outputs": [],
      "source": [
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from pathlib import Path\n",
        "\n",
        "def build_tokenizer(config, ds, lang):\n",
        "    tokenizer_path = _get_tokenizer_path(config, lang)\n",
        "\n",
        "    if not _tokenizer_exists(tokenizer_path):\n",
        "        tokenizer = _create_and_train_tokenizer(ds, lang, tokenizer_path)\n",
        "    else:\n",
        "        tokenizer = _load_tokenizer(tokenizer_path)\n",
        "\n",
        "    return tokenizer\n",
        "\n",
        "def _get_tokenizer_path(config, lang):\n",
        "    return Path(config['tokenizer_file'].format(lang))\n",
        "\n",
        "def _tokenizer_exists(tokenizer_path):\n",
        "    return tokenizer_path.exists()\n",
        "\n",
        "def _create_and_train_tokenizer(ds, lang, tokenizer_path):\n",
        "    tokenizer = _initialize_tokenizer()\n",
        "    trainer = _initialize_trainer()\n",
        "    tokenizer.train_from_iterator(_get_all_sentences(ds, lang), trainer=trainer)\n",
        "    tokenizer.save(str(tokenizer_path))\n",
        "    return tokenizer\n",
        "\n",
        "def _initialize_tokenizer():\n",
        "    tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
        "    tokenizer.pre_tokenizer = Whitespace()\n",
        "    return tokenizer\n",
        "\n",
        "def _initialize_trainer():\n",
        "    return WordLevelTrainer(special_tokens=[\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\"], min_frequency=2)\n",
        "\n",
        "def _load_tokenizer(tokenizer_path):\n",
        "    return Tokenizer.from_file(str(tokenizer_path))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oodlr4eouxTU"
      },
      "source": [
        "## Part 11: Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdVFowgUqr_Q"
      },
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">For this task, we will use the <a href = \"opus_books · Datasets at Hugging Face\">OpusBooks dataset</a>, available on 🤗Hugging Face. This dataset consists of two features, <code>id</code> and <code>translation</code>. The <code>translation</code> feature contains pairs of sentences in different languages, such as Spanish and Portuguese, English and French, and so forth.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">I first tried translating sentences from English to Portuguese—my native tongue — but there are only 1.4k examples for this pair, so the results were not satisfying in the current configurations for this model. I then tried to use the English-French pair due to its higher number of examples—127k—but it would take too long to train with the current configurations. I then opted to train the model on the English-Italian pair, the same one used in the <a href = \"https://youtu.be/ISNdQcPhsts?si=253J39cose6IdsLv\">Coding a Transformer from scratch on PyTorch, with full explanation, training and inference\n",
        "</a> video, as that was a good balance between performance and time of training.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We start by defining the <code>get_all_sentences</code> function to iterate over the dataset and extract the sentences according to the language pair defined—we will do that later.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvRuuTpIveZS"
      },
      "outputs": [],
      "source": [
        "def get_all_sentences(ds, lang):\n",
        "    for item in ds:\n",
        "        yield item['translation'][lang]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EA13IRYEqr_R"
      },
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The <code>get_ds</code> function is defined to load and prepare the dataset for training and validation. In this function, we build or load the tokenizer, split the dataset, and create DataLoaders, so the model can successfully iterate over the dataset in batches. The result of these functions is tokenizers for the source and target languages plus the DataLoader objects.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkTRqP8LvpVy"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from datasets import load_dataset\n",
        "\n",
        "def get_ds(config):\n",
        "    ds_raw = _load_raw_dataset(config)\n",
        "\n",
        "    tokenizer_src = _build_tokenizer(config, ds_raw, config['lang_src'])\n",
        "    tokenizer_tgt = _build_tokenizer(config, ds_raw, config['lang_tgt'])\n",
        "\n",
        "    train_ds, val_ds = _split_dataset(ds_raw, config)\n",
        "\n",
        "    _print_max_sentence_lengths(ds_raw, tokenizer_src, tokenizer_tgt)\n",
        "\n",
        "    train_dataloader = _create_dataloader(train_ds, config, shuffle=True)\n",
        "    val_dataloader = _create_dataloader(val_ds, config, shuffle=False)\n",
        "\n",
        "    return train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt\n",
        "\n",
        "\n",
        "def _load_raw_dataset(config):\n",
        "    return load_dataset(f\"{config['datasource']}\", f\"{config['lang_src']}-{config['lang_tgt']}\", split='train')\n",
        "\n",
        "\n",
        "def _build_tokenizer(config, ds_raw, lang):\n",
        "    return get_or_build_tokenizer(config, ds_raw, lang)\n",
        "\n",
        "\n",
        "def _split_dataset(ds_raw, config):\n",
        "    train_ds_size = int(0.9 * len(ds_raw))\n",
        "    val_ds_size = len(ds_raw) - train_ds_size\n",
        "    train_ds_raw, val_ds_raw = random_split(ds_raw, [train_ds_size, val_ds_size])\n",
        "\n",
        "    train_ds = BilingualDataset(train_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n",
        "    val_ds = BilingualDataset(val_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n",
        "\n",
        "    return train_ds, val_ds\n",
        "\n",
        "\n",
        "def _print_max_sentence_lengths(ds_raw, tokenizer_src, tokenizer_tgt):\n",
        "    max_len_src = 0\n",
        "    max_len_tgt = 0\n",
        "\n",
        "    for item in ds_raw:\n",
        "        src_ids = tokenizer_src.encode(item['translation'][config['lang_src']]).ids\n",
        "        tgt_ids = tokenizer_tgt.encode(item['translation'][config['lang_tgt']]).ids\n",
        "        max_len_src = max(max_len_src, len(src_ids))\n",
        "        max_len_tgt = max(max_len_tgt, len(tgt_ids))\n",
        "\n",
        "    print(f'Max length of source sentence: {max_len_src}')\n",
        "    print(f'Max length of target sentence: {max_len_tgt}')\n",
        "\n",
        "\n",
        "def _create_dataloader(dataset, config, shuffle):\n",
        "    return DataLoader(dataset, batch_size=config['batch_size'], shuffle=shuffle)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK3d2-AVqr_R"
      },
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We define the <code>casual_mask</code> function to create a mask for the attention mechanism of the decoder. This mask prevents the model from having information about future elements in the sequence. </p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We start by making a square grid filled with ones. We determine the grid size with the <code>size</code> parameter. Then, we change all the numbers above the main diagonal line to zeros. Every number on one side becomes a zero, while the rest remain ones. The function then flips all these values, turning ones into zeros and zeros into ones. This process is crucial for models that predict future tokens in a sequence.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTgMYaY2vvWq"
      },
      "outputs": [],
      "source": [
        "def causal_mask(size):\n",
        "    mask = torch.triu(torch.ones((1, size, size)), diagonal=1).type(torch.int)\n",
        "    return mask == 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccdK5XnMqr_R"
      },
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The <code>BilingualDataset</code> class processes the texts of the target and source languages in the dataset by tokenizing them and adding all the necessary special tokens. This class also certifies that the sentences are within a maximum sequence length for both languages and pads all necessary sentences.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9v94mdgv3y6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class BilingualDataset(Dataset):\n",
        "\n",
        "    def __init__(self, ds, tokenizer_src, tokenizer_tgt, src_lang, tgt_lang, seq_len):\n",
        "        super().__init__()\n",
        "        self.seq_len = seq_len\n",
        "        self.ds = ds\n",
        "        self.tokenizer_src = tokenizer_src\n",
        "        self.tokenizer_tgt = tokenizer_tgt\n",
        "        self.src_lang = src_lang\n",
        "        self.tgt_lang = tgt_lang\n",
        "\n",
        "        self.sos_token = torch.tensor([tokenizer_tgt.token_to_id(\"[SOS]\")], dtype=torch.int64)\n",
        "        self.eos_token = torch.tensor([tokenizer_tgt.token_to_id(\"[EOS]\")], dtype=torch.int64)\n",
        "        self.pad_token = torch.tensor([tokenizer_tgt.token_to_id(\"[PAD]\")], dtype=torch.int64)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ds)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_target_pair = self.ds[idx]\n",
        "        src_text = src_target_pair['translation'][self.src_lang]\n",
        "        tgt_text = src_target_pair['translation'][self.tgt_lang]\n",
        "\n",
        "        # Tokenize the source and target sentences\n",
        "        enc_input_tokens = self.tokenizer_src.encode(src_text).ids\n",
        "        dec_input_tokens = self.tokenizer_tgt.encode(tgt_text).ids\n",
        "\n",
        "        # Calculate padding required\n",
        "        enc_num_padding_tokens = self.seq_len - len(enc_input_tokens) - 2  # excluding <s> and </s>\n",
        "        dec_num_padding_tokens = self.seq_len - len(dec_input_tokens) - 1  # excluding <s>\n",
        "\n",
        "        if enc_num_padding_tokens < 0 or dec_num_padding_tokens < 0:\n",
        "            raise ValueError(\"Sentence is too long\")\n",
        "\n",
        "        # Construct encoder, decoder input, and label tensors\n",
        "        encoder_input = torch.cat([\n",
        "            self.sos_token,\n",
        "            torch.tensor(enc_input_tokens, dtype=torch.int64),\n",
        "            self.eos_token,\n",
        "            torch.tensor([self.pad_token] * enc_num_padding_tokens, dtype=torch.int64)\n",
        "        ], dim=0)\n",
        "\n",
        "        decoder_input = torch.cat([\n",
        "            self.sos_token,\n",
        "            torch.tensor(dec_input_tokens, dtype=torch.int64),\n",
        "            torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype=torch.int64)\n",
        "        ], dim=0)\n",
        "\n",
        "        label = torch.cat([\n",
        "            torch.tensor(dec_input_tokens, dtype=torch.int64),\n",
        "            self.eos_token,\n",
        "            torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype=torch.int64)\n",
        "        ], dim=0)\n",
        "\n",
        "        # Ensure that all tensors have the expected seq_len size\n",
        "        assert encoder_input.size(0) == self.seq_len\n",
        "        assert decoder_input.size(0) == self.seq_len\n",
        "        assert label.size(0) == self.seq_len\n",
        "\n",
        "        return {\n",
        "            \"encoder_input\": encoder_input,  # (seq_len)\n",
        "            \"decoder_input\": decoder_input,  # (seq_len)\n",
        "            \"encoder_mask\": (encoder_input != self.pad_token).unsqueeze(0).unsqueeze(0).int(),  # (1, 1, seq_len)\n",
        "            \"decoder_mask\": (decoder_input != self.pad_token).unsqueeze(0).int() & self._causal_mask(decoder_input.size(0)),  # (1, seq_len)\n",
        "            \"label\": label,  # (seq_len)\n",
        "            \"src_text\": src_text,\n",
        "            \"tgt_text\": tgt_text,\n",
        "        }\n",
        "\n",
        "    def _causal_mask(self, seq_len):\n",
        "        # Create a causal mask for the decoder (ensuring that tokens can only attend to earlier ones)\n",
        "        mask = torch.tril(torch.ones(seq_len, seq_len)).unsqueeze(0).unsqueeze(0).int()\n",
        "        return mask\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7cXlNUfv5uL"
      },
      "source": [
        "## Part 12: Validation Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf8Wt860qr_R"
      },
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We will now create two functions for the validation loop. The validation loop is crucial to evaluate model performance in translating sentences from data it has not seen during training.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We will define two functions. The first function, <code>greedy_decode</code>, gives us the model's output by obtaining the most probable next token. The second function, <code>run_validation</code>, is responsible for running the validation process in which we decode the model's output and compare it with the reference text for the target sentence.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1rzcAkpv8Ew"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def greedy_decode(model, source, source_mask, tokenizer_src, tokenizer_tgt, max_len, device):\n",
        "    sos_idx = tokenizer_tgt.token_to_id('[SOS]')\n",
        "    eos_idx = tokenizer_tgt.token_to_id('[EOS]')\n",
        "\n",
        "    encoder_output = model.encode(source, source_mask)\n",
        "    decoder_input = torch.full((1, 1), sos_idx, dtype=torch.long, device=device)\n",
        "\n",
        "    generated_tokens = torch.full((1, max_len), tokenizer_tgt.token_to_id('[PAD]'), dtype=torch.long, device=device)\n",
        "\n",
        "    for i in range(max_len):\n",
        "        decoder_mask = causal_mask(decoder_input.size(1)).type_as(source_mask).to(device)\n",
        "        out = model.decode(encoder_output, source_mask, decoder_input, decoder_mask)\n",
        "        prob = model.project(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        decoder_input = torch.cat([decoder_input, next_word.unsqueeze(0).unsqueeze(0)], dim=1)\n",
        "        generated_tokens[:, i] = next_word\n",
        "        if next_word == eos_idx:\n",
        "            break\n",
        "\n",
        "    return generated_tokens.squeeze(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iF7v9L0owcLT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "def run_validation(model, validation_ds, tokenizer_src, tokenizer_tgt, max_len, device, print_msg, global_step, writer, num_examples=2):\n",
        "    model.eval()\n",
        "    count = 0\n",
        "\n",
        "    source_texts = []\n",
        "    expected = []\n",
        "    predicted = []\n",
        "\n",
        "    try:\n",
        "        with os.popen('stty size', 'r') as console:\n",
        "            _, console_width = console.read().split()\n",
        "            console_width = int(console_width)\n",
        "    except:\n",
        "        console_width = 80\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in validation_ds:\n",
        "            count += 1\n",
        "            encoder_input = batch[\"encoder_input\"].to(device)\n",
        "            encoder_mask = batch[\"encoder_mask\"].to(device)\n",
        "\n",
        "            assert encoder_input.size(0) == 1\n",
        "\n",
        "            model_out = greedy_decode(model, encoder_input, encoder_mask, tokenizer_src, tokenizer_tgt, max_len, device)\n",
        "\n",
        "            source_text = batch[\"src_text\"][0]\n",
        "            target_text = batch[\"tgt_text\"][0]\n",
        "            model_out_text = tokenizer_tgt.decode(model_out.detach().cpu().numpy())\n",
        "\n",
        "            source_texts.append(source_text)\n",
        "            expected.append(target_text)\n",
        "            predicted.append(model_out_text)\n",
        "\n",
        "            print_msg('-'*console_width)\n",
        "            print_msg(f\"{f'SOURCE: ':>12}{source_text}\")\n",
        "            print_msg(f\"{f'TARGET: ':>12}{target_text}\")\n",
        "            print_msg(f\"{f'PREDICTED: ':>12}{model_out_text}\")\n",
        "\n",
        "            if count == num_examples:\n",
        "                print_msg('-'*console_width)\n",
        "                break\n",
        "\n",
        "    if writer:\n",
        "        metric = torchmetrics.CharErrorRate()\n",
        "        cer = metric(predicted, expected)\n",
        "        writer.add_scalar('validation cer', cer, global_step)\n",
        "        writer.flush()\n",
        "\n",
        "        metric = torchmetrics.WordErrorRate()\n",
        "        wer = metric(predicted, expected)\n",
        "        writer.add_scalar('validation wer', wer, global_step)\n",
        "        writer.flush()\n",
        "\n",
        "        metric = torchmetrics.BLEUScore()\n",
        "        bleu = metric(predicted, expected)\n",
        "        writer.add_scalar('validation BLEU', bleu, global_step)\n",
        "        writer.flush()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw3nykKxwkIh"
      },
      "source": [
        "## Part 13: Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az_Kwq4Zqr_S"
      },
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We are ready to train our Transformer model on the OpusBook dataset for the English to Italian translation task.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We first start by defining the <code>get_model</code> function to load the model by calling the <code>build_transformer</code> function we have previously defined. This function uses the <code>config</code> dictionary to set a few parameters.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QMn1BULwnBl"
      },
      "outputs": [],
      "source": [
        "def get_model(config, vocab_src_len, vocab_tgt_len):\n",
        "    model = build_transformer(vocab_src_len, vocab_tgt_len, config[\"seq_len\"], config['seq_len'], d_model=config['d_model'])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ord2DlVkqr_S"
      },
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">I have mentioned the <code>config</code> dictionary several times throughout this notebook. Now, it is time to create it.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the following cell, we will define two functions to configure our model and the training process.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the <code>get_config</code> function, we define crucial parameters for the training process. <code>batch_size</code> for the number of training examples used in one iteration, <code>num_epochs</code> as the number of times the entire dataset is passed forward and backward through the Transformer, <code>lr</code> as the learning rate for the optimizer, etc. We will also finally define the pairs from the OpusBook dataset, <code>'lang_src': 'en'</code> for selecting English as the source language and <code>'lang_tgt': 'it'</code> for selecting Italian as the target language.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The <code>get_weights_file_path</code> function constructs the file path for saving or loading model weights for any specific epoch.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXt82CejxeHZ"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def get_config():\n",
        "    return {\n",
        "        \"batch_size\": 8,\n",
        "        \"num_epochs\": 5,\n",
        "        \"lr\": 10**-4,\n",
        "        \"seq_len\": 350,\n",
        "        \"d_model\": 512,\n",
        "        \"datasource\": 'opus_books',\n",
        "        \"lang_src\": \"en\",\n",
        "        \"lang_tgt\": \"it\",\n",
        "        \"model_folder\": \"weights\",\n",
        "        \"model_basename\": \"tmodel_\",\n",
        "        \"preload\": \"latest\",\n",
        "        \"tokenizer_file\": \"tokenizer_{0}.json\",\n",
        "        \"experiment_name\": \"runs/tmodel\"\n",
        "    }\n",
        "\n",
        "def get_weights_file_path(config, epoch: str):\n",
        "    model_folder = f\"{config['datasource']}_{config['model_folder']}\"\n",
        "    model_filename = f\"{config['model_basename']}{epoch}.pt\"\n",
        "    return str(Path('.') / model_folder / model_filename)\n",
        "\n",
        "def latest_weights_file_path(config):\n",
        "    model_folder = f\"{config['datasource']}_{config['model_folder']}\"\n",
        "    model_filename = f\"{config['model_basename']}*\"\n",
        "    weights_files = list(Path(model_folder).glob(model_filename))\n",
        "    if len(weights_files) == 0:\n",
        "        return None\n",
        "    weights_files.sort()\n",
        "    return str(weights_files[-1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qw7SjmrDqr_S"
      },
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We finally define our last function, <code>train_model</code>, which takes the <code>config</code> arguments as input. </p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In this function, we will set everything up for the training. We will load the model and its necessary components onto the GPU for faster training, set the <code>Adam</code> optimizer, and configure the <code>CrossEntropyLoss</code> function to compute the differences between the translations output by the model and the reference translations from the dataset. </p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">Every loop necessary for iterating over the training batches, performing backpropagation, and computing the gradients is in this function. We will also use it to run the validation function and save the current state of the model.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qK9wAjRxoDQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import os\n",
        "\n",
        "def train_model(config):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.has_mps or torch.backends.mps.is_available() else \"cpu\"\n",
        "    print(\"Using device:\", device)\n",
        "    if (device == 'cuda'):\n",
        "        print(f\"Device name: {torch.cuda.get_device_name(device.index)}\")\n",
        "        print(f\"Device memory: {torch.cuda.get_device_properties(device.index).total_memory / 1024 ** 3} GB\")\n",
        "    elif (device == 'mps'):\n",
        "        print(f\"Device name: <mps>\")\n",
        "    else:\n",
        "        print(\"NOTE: If you have a GPU, consider using it for training.\")\n",
        "        print(\"      On a Windows machine with NVidia GPU, check this video: https://www.youtube.com/watch?v=GMSjDTU8Zlc\")\n",
        "        print(\"      On a Mac machine, run: pip3 install --pre torch torchvision torchaudio torchtext --index-url https://download.pytorch.org/whl/nightly/cpu\")\n",
        "    device = torch.device(device)\n",
        "\n",
        "    Path(f\"{config['datasource']}_{config['model_folder']}\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)\n",
        "    model = get_model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n",
        "    writer = SummaryWriter(config['experiment_name'])\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], eps=1e-9)\n",
        "\n",
        "    initial_epoch = 0\n",
        "    global_step = 0\n",
        "    preload = config['preload']\n",
        "    model_filename = latest_weights_file_path(config) if preload == 'latest' else get_weights_file_path(config, preload) if preload else None\n",
        "    if model_filename:\n",
        "        print(f'Preloading model {model_filename}')\n",
        "        state = torch.load(model_filename)\n",
        "        model.load_state_dict(state['model_state_dict'])\n",
        "        initial_epoch = state['epoch'] + 1\n",
        "        optimizer.load_state_dict(state['optimizer_state_dict'])\n",
        "        global_step = state['global_step']\n",
        "    else:\n",
        "        print('No model to preload, starting from scratch')\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer_src.token_to_id('[PAD]'), label_smoothing=0.1).to(device)\n",
        "\n",
        "    for epoch in range(initial_epoch, config['num_epochs']):\n",
        "        torch.cuda.empty_cache()\n",
        "        model.train()\n",
        "        batch_iterator = tqdm(train_dataloader, desc=f\"Processing Epoch {epoch:02d}\")\n",
        "        for batch in batch_iterator:\n",
        "\n",
        "            encoder_input = batch['encoder_input'].to(device)\n",
        "            decoder_input = batch['decoder_input'].to(device)\n",
        "            encoder_mask = batch['encoder_mask'].to(device)\n",
        "            decoder_mask = batch['decoder_mask'].to(device)\n",
        "\n",
        "            encoder_output = model.encode(encoder_input, encoder_mask)\n",
        "            decoder_output = model.decode(encoder_output, encoder_mask, decoder_input, decoder_mask)\n",
        "            proj_output = model.project(decoder_output)\n",
        "\n",
        "            label = batch['label'].to(device)\n",
        "\n",
        "            loss = loss_fn(proj_output.view(-1, tokenizer_tgt.get_vocab_size()), label.view(-1))\n",
        "            batch_iterator.set_postfix({\"loss\": f\"{loss.item():6.3f}\"})\n",
        "\n",
        "            writer.add_scalar('train loss', loss.item(), global_step)\n",
        "            writer.flush()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "        run_validation(model, val_dataloader, tokenizer_src, tokenizer_tgt, config['seq_len'], device, lambda msg: batch_iterator.write(msg), global_step, writer)\n",
        "\n",
        "        model_filename = get_weights_file_path(config, f\"{epoch:02d}\")\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'global_step': global_step\n",
        "        }, model_filename)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrMmfyi8xrXw"
      },
      "source": [
        "We can now train the model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "19f1d87a8f2440e2a649fa1f1b31d2a4",
            "191bcf61d97048df8fc80d2bf4239032",
            "8a53a9f3ae67453b93d891fbf8d94006",
            "4b606598fd4149d4abee122bd347314c",
            "e23e6982ef2e424888839815130cb8a5",
            "a7e35a425831469781d2801e5c0f0c46",
            "37dcd52c6d4d435691ba1cdb99a900e8",
            "33534b9cbbe244a289643b1fc1459806",
            "8046cc16e97d48fa86831841bb0364e5",
            "558836b657ab49b9825b5aff2b697efe",
            "3eb657598dd64d0c9c4eb4f8556c8348",
            "fd8308f41d3e4a7793b5d5910a6dd2cd",
            "e623e0ad546f431a8a8e9976c3edd3e7",
            "a7b7b53b11ff4da5963fdb9f7c9c96da",
            "92ccba7af5f048808c30ebcc85ff9ad3",
            "020abce58cf143fe91fe7657c94ed57a",
            "19a4bd1c26a64c73892883ecf845603f",
            "ad896f0e5dea477c92553f959baa5d87",
            "6d277c340f09424a837f6938cd9c2b0f",
            "30f3c7ccb1ba4024becf1bd517233d25",
            "90c17936e09e485388b78c1fd6fd0353",
            "83026d18a9284dfdb6f5f394afe4a295",
            "62eecadd783d4c4ebc64320a6795e5ee",
            "9ec149d09634422ea3c43ead572e6ab1",
            "ba646af747784fe997c3ded6f4d8ae8e",
            "12266c1060fd41ce836408098d95b7a8",
            "8b2257ef94c449df84bf50e3e3dec13f",
            "f405fd82b5634a4ea0b2207227e6cf7f",
            "2c4bd7bffdb94066981ff6fae0d5e36e",
            "5449a611e4e54265bf5a0fb9389f39f9",
            "73bfc0a51843402ab4b305501104106c",
            "f340eb5d8ca8401bbc349e49909dd9e1",
            "9f58db67f6e54aa5a4201849524da0d1"
          ]
        },
        "id": "28425EYaxrsi",
        "outputId": "0b4b1749-bff9-40aa-a321-20316a81b643"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.1+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Downloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.9 torchmetrics-1.6.1\n",
            "Using device: cuda\n",
            "Device name: Tesla T4\n",
            "Device memory: 14.74810791015625 GB\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19f1d87a8f2440e2a649fa1f1b31d2a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/28.1k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd8308f41d3e4a7793b5d5910a6dd2cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/5.73M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62eecadd783d4c4ebc64320a6795e5ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/32332 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max length of source sentence: 309\n",
            "Max length of target sentence: 274\n",
            "No model to preload, starting from scratch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 00: 100%|██████████| 3638/3638 [25:10<00:00,  2.41it/s, loss=6.398]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: All the inhabitants of Hampton and Moulsey dress themselves up in boating costume, and come and mouch round the lock with their dogs, and flirt, and smoke, and watch the boats; and, altogether, what with the caps and jackets of the men, the pretty coloured dresses of the women, the excited dogs, the moving boats, the white sails, the pleasant landscape, and the sparkling water, it is one of the gayest sights I know of near this dull old London town.\n",
            "    TARGET: Tutti gli abitanti di Hampton e di Moulsey si vestono in costume fluviale e vanno a gironzare intorno al fiume con i loro cani, e corteggiano le ragazze, fremono e guardano le barche; e fra i berretti e le giacche degli nomini, le belle acconciature colorate delle donne, i latrati festosi dei cani, le barche che passano, le vele bianche, il bel panorama e lo scintillio dell’acqua, si gode assolutamente uno dei più bei spettacoli visibili nei pressi di questa vecchia e fosca città di Londra.\n",
            " PREDICTED: , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e a , e , e , e , e , e a a a , e a , e , e , e , e a a a , e , e , e a a , e , e , e a a a a a a , e , e , e , e , e , e a a , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: Kitty glanced at her sister, but the cold and rather severe expression of her face did not change.\n",
            "    TARGET: Kitty guardò la sorella e l’espressione fredda, un po’ dura del viso non mutò.\n",
            " PREDICTED: Levin era un ’ ja Aleksandrovna , e si fermò , e si fermò , e si fermò .\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 01: 100%|██████████| 3638/3638 [25:08<00:00,  2.41it/s, loss=5.347]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: The landowner smiled under his grey moustache.\n",
            "    TARGET: Il proprietario sorrise sotto i baffi bianchi.\n",
            " PREDICTED: La principessa , il viso di Aleksej Aleksandrovic , il viso di un sorriso .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: 'It can't be helped, I have an appointment there in connection with this same peacemaking of mine.'\n",
            "    TARGET: — Che fare? Ho un appuntamento là, sempre per questa mia opera di pace.\n",
            " PREDICTED: — Non è nulla di più di me , ma io non mi .\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 02: 100%|██████████| 3638/3638 [25:06<00:00,  2.42it/s, loss=5.271]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: Alice was more and more puzzled, but she thought there was no use in saying anything more till the Pigeon had finished.\n",
            "    TARGET: Alice sempre più confusa, pensò che sarebbe stato inutile dir nulla, sin che il Colombo non avesse finito.\n",
            " PREDICTED: Alice era un poco , ma non era più più che non era più di .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: Nothing special was said during the quadrille: they talked in snatches about the Korsunskys, husband and wife, whom Vronsky very amusingly described as dear forty-year-old children, and about a proposed Stage Society, and only once did the conversation touch her to the quick – when he asked her about Levin, whether he was still in Moscow, and added that he had liked him very much.\n",
            "    TARGET: Durante la quadriglia non fu detto nulla di particolare. La conversazione, smozzicata, si aggirò ora sui Korsunskij, marito e moglie, che Vronskij descriveva, con molta amenità, come cari ragazzi quarantenni, ora sul futuro teatro pubblico, e solo una volta la toccò nel vivo, quando egli le chiese se c’era Levin e soggiunse che gli era piaciuto molto.\n",
            " PREDICTED: Ma , come era stato molto , ma , per la moglie , e la moglie , la moglie , e la moglie , per la sua moglie , e la sua , Levin , e , come se era stato un ’ altra , e , come se non era stato di Levin , e che , e , come se non era stato possibile , e che non aveva mai fatto nulla .\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 03: 100%|██████████| 3638/3638 [25:09<00:00,  2.41it/s, loss=5.086]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: What could my darling do, I asked, left destitute and penniless?\n",
            "    TARGET: \"Mi domandavo che cosa avrebbe fatto la mia cara, povera e abbandonata.\n",
            " PREDICTED: Che cosa mi domandò , e io mi ?\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: And that you should hire horses in the village is, in the first place, unpleasant to me, and besides that, they will undertake the job but won't get you there.\n",
            "    TARGET: E poi, prenderli in affitto al paese, in primo luogo mi rincresce, e poi anche se prenderanno l’incarico, non ti porteranno fin là.\n",
            " PREDICTED: E voi , che la barca è la prima volta , è stata , e che io non si , e che io non .\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 04: 100%|██████████| 3638/3638 [25:08<00:00,  2.41it/s, loss=4.754]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: 'It is worse than cruelty, it is – baseness, if you want to know!' Anna exclaimed in a burst of anger, and rose to go.\n",
            "    TARGET: — È peggiore della crudeltà, questa è vigliaccheria, se volete saperlo — gridò Anna in uno scoppio di rabbia e, alzatasi, fece per andar via.\n",
            " PREDICTED: — È più difficile , per voi , è vero , per voi , se tu non — gridò Anna , guardandolo con un sorriso .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: Now I am sure of it.'\n",
            "    TARGET: È questo che io so, adesso.\n",
            " PREDICTED: Ora sono molto contenta .\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# from torch.utils.data import Dataset, DataLoader, random_split\n",
        "# from torch.optim.lr_scheduler import LambdaLR\n",
        "\n",
        "# import warnings\n",
        "# from tqdm import tqdm\n",
        "# import os\n",
        "# from pathlib import Path\n",
        "\n",
        "# # Huggingface datasets and tokenizers\n",
        "# from datasets import load_dataset\n",
        "# from tokenizers import Tokenizer\n",
        "# from tokenizers.models import WordLevel\n",
        "# from tokenizers.trainers import WordLevelTrainer\n",
        "# from tokenizers.pre_tokenizers import Whitespace\n",
        "!pip install torchmetrics\n",
        "\n",
        "import torchmetrics\n",
        "# from torch.utils.tensorboard import SummaryWriter\n",
        "# !pip install numpy==1.26.0\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    config = get_config()\n",
        "    train_model(config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3axMN7QWiVH"
      },
      "source": [
        "# Section 2: BERT and LoRA\n",
        "\n",
        "Welcome to Section 2 of our Machine Learning assignment! I hope you've been enjoying the journey so far! 😊\n",
        "\n",
        " In this section, you will gain hands-on experience with [BERT](https://arxiv.org/abs/1810.04805) (Bidirectional Encoder Representations from Transformers) and [LoRA](https://arxiv.org/abs/2106.09685) (Low-Rank Adaptation) for text classification tasks. The section is divided into three main parts, each focusing on different aspects of NLP techniques.\n",
        "\n",
        "## Assignment Structure\n",
        "\n",
        "### Part 1: Data Preparation and Preprocessing\n",
        "In this part, you will work with a text classification dataset. You will learn how to:\n",
        "- Download and load the dataset\n",
        "- Perform necessary preprocessing steps\n",
        "- Implement data cleaning and transformation techniques\n",
        "- Prepare the data in a format suitable for BERT training\n",
        "\n",
        "### Part 2: Building a Small BERT Model\n",
        "You will create and train a small BERT model from scratch using the Hugging Face [Transformers](https://huggingface.co/docs/transformers/en/index) library. This part will help you understand:\n",
        "- The architecture of BERT\n",
        "- How to configure and initialize a BERT model\n",
        "- Training process and optimization\n",
        "- Model evaluation and performance analysis\n",
        "\n",
        "### Part 3: Fine-tuning with LoRA\n",
        "In the final part, you will work with a pre-trained [TinyBERT](https://arxiv.org/abs/1909.10351) model and use LoRA for efficient fine-tuning. You will:\n",
        "- Load a pre-trained TinyBERT model\n",
        "- Implement LoRA adaptation and fine-tune the model on our classification task\n",
        "- Compare the results with the previous approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6FKcSFbOTMd"
      },
      "source": [
        "---\n",
        "\n",
        "> **NOTE**:  \n",
        "> Throughout this notebook, make an effort to include sufficient visualizations to enhance understanding:  \n",
        "> - In the data processing section, display the results of your operations (e.g., show data samples or distributions after preprocessing).  \n",
        "> - In the classification section, report various evaluation metrics such as accuracy, precision, recall, and F1-score to thoroughly assess your model's performance.  \n",
        "> - Additionally, take a moment to compare the sizes of the models discussed in this notebook with today’s enormous models. This will help you appreciate the challenges and computational demands associated with training such massive models. 😵‍💫\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHKw2r6yYV7n"
      },
      "source": [
        "## Part 1: Data Preparation and Preprocessing\n",
        "We'll be working with the [Consumer Complaint](https://catalog.data.gov/dataset/consumer-complaint-database) dataset, which contains ***complaints*** submitted by consumers about financial products and services. Our goal is to build a classifier that can automatically identify the type of complaint based on the consumer's text description. For this task, we will work with a smaller subset of the dataset, available for download through this [link](https://drive.google.com/file/d/1SpIHksR-WzruEgUjp1SQKGG8bZPnJJoN/view?usp=sharing)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ELMR8kXUh3o"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oJXlKLYeymq"
      },
      "source": [
        "### 1.2 Loading the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGga8BmnUcl0",
        "outputId": "dce2d23d-cd07-4b05-d6fe-cea40d70f09d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Overview:\n",
            "                                             Product  \\\n",
            "0  Credit reporting, credit repair services, or o...   \n",
            "1                                       Student loan   \n",
            "2  Credit reporting or other personal consumer re...   \n",
            "3  Credit reporting, credit repair services, or o...   \n",
            "4  Credit reporting or other personal consumer re...   \n",
            "\n",
            "                        Consumer complaint narrative  \n",
            "0  My credit reports are inaccurate. These inaccu...  \n",
            "1  Beginning in XX/XX/XXXX I had taken out studen...  \n",
            "2  I am disputing a charge-off on my account that...  \n",
            "3  I did not consent to, authorize, nor benefit f...  \n",
            "4  I am a federally protected consumer and I am a...  \n",
            "\n",
            "Dataset Columns:\n",
            "Index(['Product', 'Consumer complaint narrative'], dtype='object')\n",
            "\n",
            "Dataset Shape:\n",
            "(36405, 2)\n",
            "\n",
            "Missing Values per Column:\n",
            "Product                         0\n",
            "Consumer complaint narrative    1\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "# Load the dataset\n",
        "# Load the dataset\n",
        "data_path = \"./complaints_small.csv\"\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(\"Dataset Overview:\")\n",
        "print(df.head())\n",
        "print(\"\\nDataset Columns:\")\n",
        "print(df.columns)\n",
        "print(\"\\nDataset Shape:\")\n",
        "print(df.shape)\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing Values per Column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9hr8-FNgpVO"
      },
      "source": [
        "### 1.3 Data Sampling and Class Distribution Analysis\n",
        "\n",
        "Working with large datasets can be computationally intensive during development. Additionally, imbalanced class distribution can affect model performance. In this section, you'll sample the data and analyze class distributions to make informed decisions about your training dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl_g_ZU4h5RG"
      },
      "source": [
        "---\n",
        "\n",
        "We'll work with a manageable portion of the data to develop and test our approach. While using the complete dataset would likely yield better results, a smaller sample allows us to prototype our solution more efficiently.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAJUXNCFhYsf",
        "outputId": "69d1fb5d-1b61-4a41-9c1a-bb6c100b5c08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled Dataset Overview:\n",
            "                                                 Product  \\\n",
            "24443  Credit reporting or other personal consumer re...   \n",
            "16321  Credit reporting, credit repair services, or o...   \n",
            "12657  Credit reporting, credit repair services, or o...   \n",
            "31695                                           Mortgage   \n",
            "8499   Credit reporting or other personal consumer re...   \n",
            "\n",
            "                            Consumer complaint narrative  \n",
            "24443  an inaccurate and unverified charge-off on my ...  \n",
            "16321  There are accounts on my credit report that ar...  \n",
            "12657  It has been drawn out into the open that you a...  \n",
            "31695  This is the XXXX complaint I have filed agains...  \n",
            "8499   I've learned that the creditor didn't provide ...  \n",
            "\n",
            "Original Dataset Shape: (36405, 2)\n",
            "Sampled Dataset Shape: (7281, 2)\n",
            "No label column specified. Please replace 'label_column' with the actual column name.\n"
          ]
        }
      ],
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "# - Sample a portion of the complete dataset\n",
        "# - Display the first few rows of your sampled dataset\n",
        "# - Print the shape of your original and sampled datasets\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "sampled_df = df.sample(frac=0.2, random_state=42)  # Adjust the fraction as needed\n",
        "\n",
        "print(\"Sampled Dataset Overview:\")\n",
        "print(sampled_df.head())\n",
        "\n",
        "print(f\"\\nOriginal Dataset Shape: {df.shape}\")\n",
        "print(f\"Sampled Dataset Shape: {sampled_df.shape}\")\n",
        "\n",
        "if 'label_column' in df.columns:  # Replace 'label_column' with the actual column name for labels\n",
        "    print(\"\\nClass Distribution in Original Dataset:\")\n",
        "    print(df['label_column'].value_counts(normalize=True))\n",
        "\n",
        "    print(\"\\nClass Distribution in Sampled Dataset:\")\n",
        "    print(sampled_df['label_column'].value_counts(normalize=True))\n",
        "else:\n",
        "    print(\"No label column specified. Please replace 'label_column' with the actual column name.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50a4NJeMiBb6"
      },
      "source": [
        "---\n",
        "\n",
        "Let's examine the distribution of ***complaints*** types in our dataset. You'll notice that some products have significantly more instances than others, and some categories are quite similar. For example:\n",
        "\n",
        "- Multiple categories might refer to similar financial products\n",
        "- Some categories might have very few examples\n",
        "- Certain categories might be subcategories of others\n",
        "\n",
        "You have two main approaches to handle this situation:\n",
        "\n",
        "1. **Merging Similar Classes:** Identify categories that represent similar products/services and Combine them to create more robust, general categories\n",
        "\n",
        "2. **Selecting Major Classes:** Only select the categories with sufficient representation\n",
        "\n",
        "\n",
        "\n",
        "> You may choose any approach, but after this step, your data must include **at least five** distinct classes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nby2Hrwwjd46",
        "outputId": "be5e37d9-70b4-4083-fb51-498475aea26b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available Columns in Dataset:\n",
            "Index(['Product', 'Consumer complaint narrative'], dtype='object')\n",
            "\n",
            "Detected target column: Product\n",
            "\n",
            "Class Distribution in Original Dataset:\n",
            "Product\n",
            "Credit reporting, credit repair services, or other personal consumer reports    12470\n",
            "Credit reporting or other personal consumer reports                              9795\n",
            "Debt collection                                                                  4568\n",
            "Mortgage                                                                         1906\n",
            "Checking or savings account                                                      1728\n",
            "Credit card or prepaid card                                                      1607\n",
            "Credit card                                                                       970\n",
            "Student loan                                                                      735\n",
            "Money transfer, virtual currency, or money service                                696\n",
            "Vehicle loan or lease                                                             514\n",
            "Credit reporting                                                                  511\n",
            "Payday loan, title loan, or personal loan                                         274\n",
            "Bank account or service                                                           200\n",
            "Consumer Loan                                                                     154\n",
            "Payday loan, title loan, personal loan, or advance loan                           105\n",
            "Prepaid card                                                                       95\n",
            "Payday loan                                                                        37\n",
            "Money transfers                                                                    17\n",
            "Debt or credit management                                                          14\n",
            "Other financial service                                                             7\n",
            "Virtual currency                                                                    1\n",
            "Credit                                                                              1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Underrepresented Classes (less than 50 instances):\n",
            "['Payday loan', 'Money transfers', 'Debt or credit management', 'Other financial service', 'Virtual currency', 'Credit ']\n",
            "\n",
            "Class Distribution After Handling Imbalance:\n",
            "Product\n",
            "Credit reporting, credit repair services, or other personal consumer reports    12470\n",
            "Credit reporting or other personal consumer reports                              9795\n",
            "Debt collection                                                                  4568\n",
            "Mortgage                                                                         1906\n",
            "Checking or savings account                                                      1728\n",
            "Credit card or prepaid card                                                      1607\n",
            "Student loan                                                                      735\n",
            "Money transfer, virtual currency, or money service                                696\n",
            "Vehicle loan or lease                                                             514\n",
            "Payday loan, title loan, or personal loan                                         274\n",
            "Bank account or service                                                           200\n",
            "Consumer Loan                                                                     154\n",
            "Payday loan, title loan, personal loan, or advance loan                           105\n",
            "Prepaid card                                                                       95\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Number of Unique Classes After Processing: 14\n"
          ]
        }
      ],
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "# - Display the number of complaints in each product category\n",
        "# - Identify which classes are under-represented\n",
        "\n",
        "# - Handle class imbalance by choosing and implementing one of these approaches:\n",
        "#   1. Merge similar product categories (e.g., combining related categories)\n",
        "#   2. Keep only the major classes with sufficient examples\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "print(\"Available Columns in Dataset:\")\n",
        "print(df.columns)\n",
        "\n",
        "target_column = None\n",
        "for col in df.columns:\n",
        "    if \"product\" in col.lower() or \"category\" in col.lower():\n",
        "        target_column = col\n",
        "        break\n",
        "\n",
        "if target_column:\n",
        "    print(f\"\\nDetected target column: {target_column}\")\n",
        "\n",
        "    print(\"\\nClass Distribution in Original Dataset:\")\n",
        "    print(df[target_column].value_counts())\n",
        "\n",
        "    class_counts = df[target_column].value_counts()\n",
        "    threshold = 50  # Adjust this based on your dataset\n",
        "    underrepresented_classes = class_counts[class_counts < threshold].index.tolist()\n",
        "\n",
        "    print(f\"\\nUnderrepresented Classes (less than {threshold} instances):\")\n",
        "    print(underrepresented_classes)\n",
        "\n",
        "    merge_mapping = {\n",
        "        'Credit reporting': 'Credit Services',\n",
        "        'Credit card': 'Credit Services',\n",
        "        'Payday loan': 'Loans',\n",
        "        'Vehicle loan': 'Loans',\n",
        "    }\n",
        "    df[target_column] = df[target_column].replace(merge_mapping)\n",
        "\n",
        "    major_classes = class_counts[class_counts >= threshold].index.tolist()\n",
        "    df_filtered = df[df[target_column].isin(major_classes)]\n",
        "\n",
        "    print(\"\\nClass Distribution After Handling Imbalance:\")\n",
        "    print(df_filtered[target_column].value_counts())\n",
        "\n",
        "    unique_classes = df_filtered[target_column].nunique()\n",
        "    print(f\"\\nNumber of Unique Classes After Processing: {unique_classes}\")\n",
        "\n",
        "else:\n",
        "    print(\"No suitable column found for complaints classification. Please check your dataset.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD3oISsijt1P"
      },
      "source": [
        "---\n",
        "### 1.4 Data Encoding and Text Preprocessing\n",
        "\n",
        "Before training our model, we need to prepare both our target labels and text data. This involves converting categorical labels into numerical format and cleaning our text data to improve model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAmaRU92mGyT",
        "outputId": "a74bcba9-b07e-4057-9f21-ea632d0a85ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label Mapping:\n",
            "{'Bank account or service': 0, 'Checking or savings account': 1, 'Consumer Loan': 2, 'Credit card or prepaid card': 3, 'Credit reporting or other personal consumer reports': 4, 'Credit reporting, credit repair services, or other personal consumer reports': 5, 'Debt collection': 6, 'Money transfer, virtual currency, or money service': 7, 'Mortgage': 8, 'Payday loan, title loan, or personal loan': 9, 'Payday loan, title loan, personal loan, or advance loan': 10, 'Prepaid card': 11, 'Student loan': 12, 'Vehicle loan or lease': 13}\n",
            "\n",
            "Processed Data Sample:\n",
            "                                        cleaned_text  \\\n",
            "0  my credit reports are inaccurate these inaccur...   \n",
            "1  beginning in xxxxxxxx i had taken out student ...   \n",
            "2  i am disputing a chargeoff on my account that ...   \n",
            "3  i did not consent to authorize nor benefit fro...   \n",
            "4  i am a federally protected consumer and i am a...   \n",
            "\n",
            "                                             Product  label_encoded  \n",
            "0  Credit reporting, credit repair services, or o...              5  \n",
            "1                                       Student loan             12  \n",
            "2  Credit reporting or other personal consumer re...              4  \n",
            "3  Credit reporting, credit repair services, or o...              5  \n",
            "4  Credit reporting or other personal consumer re...              4  \n",
            "\n",
            "Final Dataset Shape After Preprocessing: (34575, 4)\n"
          ]
        }
      ],
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "# Label Encoding\n",
        "# - Apply label encoding to convert product categories into numeric values\n",
        "\n",
        "# Text Preprocessing\n",
        "# Choose and implement preprocessing steps that you think will improve the quality of your text data.\n",
        "# Here are some suggestions:\n",
        "\n",
        "# - Remove special characters and punctuation\n",
        "# - Remove very short complaints (e.g., less than 10 words)\n",
        "# - Remove HTML tags if present\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import re\n",
        "\n",
        "text_column = \"Consumer complaint narrative\"\n",
        "target_column = \"Product\"\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df_filtered['label_encoded'] = label_encoder.fit_transform(df_filtered[target_column])\n",
        "\n",
        "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "print(\"Label Mapping:\")\n",
        "print(label_mapping)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if pd.isnull(text):\n",
        "        return \"\"  # Handle missing values gracefully\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    text = text.lower()\n",
        "\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "df_filtered['cleaned_text'] = df_filtered[text_column].apply(preprocess_text)\n",
        "\n",
        "df_filtered = df_filtered[df_filtered['cleaned_text'].apply(lambda x: len(x.split()) >= 10)]\n",
        "\n",
        "print(\"\\nProcessed Data Sample:\")\n",
        "print(df_filtered[['cleaned_text', target_column, 'label_encoded']].head())\n",
        "\n",
        "print(f\"\\nFinal Dataset Shape After Preprocessing: {df_filtered.shape}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4jVvN4oopUU"
      },
      "source": [
        "## 1.5 Dataset Creation and Tokenization\n",
        "\n",
        "For training our BERT model, we need to:\n",
        "1. Create a custom Dataset class that will handle tokenization\n",
        "2. Split the data into training and testing sets\n",
        "3. Use BERT's tokenizer to convert text into a format suitable for the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHLQgJhopEh5"
      },
      "outputs": [],
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "class ComplaintDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=512):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),  # Remove batch dimension\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-js5x8M5mksA",
        "outputId": "36aefbc5-b98b-4a77-da74-f64ebd157e15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample Batch:\n",
            "Input IDs: torch.Size([16, 512])\n",
            "Attention Mask: torch.Size([16, 512])\n",
            "Labels: torch.Size([16])\n"
          ]
        }
      ],
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df_filtered['cleaned_text'].tolist(),\n",
        "    df_filtered['label_encoded'].tolist(),\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "train_dataset = ComplaintDataset(X_train, y_train, tokenizer)\n",
        "test_dataset = ComplaintDataset(X_test, y_test, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "for batch in train_loader:\n",
        "    print(\"\\nSample Batch:\")\n",
        "    print(\"Input IDs:\", batch['input_ids'].shape)\n",
        "    print(\"Attention Mask:\", batch['attention_mask'].shape)\n",
        "    print(\"Labels:\", batch['labels'].shape)\n",
        "    break\n",
        "\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMcc2gsbt0iJ"
      },
      "source": [
        "## Part 2: Training a Small-Size BERT Model\n",
        "\n",
        "In this part, we will explore how to build and train a small-sized BERT model for our classification task. Instead of using the full-sized BERT model, which is computationally expensive, we will create a smaller version using the Transformers library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RS5oBz3qmvu",
        "outputId": "88b0b7bf-59a0-44f8-b565-98a560ecc75a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total Trainable Parameters: 109493006\n"
          ]
        }
      ],
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "# 1. Define your BERT model for sequence classification\n",
        "#    Ensure that you set up the configuration properly (e.g., specify the number of output labels).\n",
        "# 2. Print the total number of trainable parameters in the model to understand its size.\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "import torch\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "num_labels = len(label_mapping)  # Automatically set based on the number of classes\n",
        "model_config = BertConfig.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', config=model_config)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"\\nTotal Trainable Parameters: {total_params}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr4Z14a6wL2c"
      },
      "source": [
        "---\n",
        "\n",
        "Now that you have defined your model, it's time to train it!☠️\n",
        "\n",
        "Training a model of this size can take some time, depending on the available resources. To manage this, you can train your model for just **2–3 epochs** to demonstrate progress. Here are some hints:\n",
        "- **Training Metrics:** Ensure you print enough metrics, such as loss and accuracy, to track the training progress.\n",
        "- **Interactive Monitoring:** Use the `tqdm` library to display the progress of your training loop in real-time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRZW-F9Dw6AI",
        "outputId": "2ec579ca-0c37-4b7b-f3a5-8996aab4a618"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Epoch 1/3 - Training:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1729/1729 [44:38<00:00,  1.55s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1 - Loss: 0.9690, Accuracy: 0.6503\n",
            "\n",
            "Epoch 2/3 - Training:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 1726/1729 [44:29<00:04,  1.56s/it]"
          ]
        }
      ],
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "num_epochs = 3\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    print(f\"\\nEpoch {epoch + 1}/{num_epochs} - Training:\")\n",
        "    for batch in tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Move batch to the same device as the model\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        # Calculate loss and accuracy\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "        correct += (predictions == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Print epoch metrics\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    accuracy = correct / total_samples\n",
        "    print(f\"\\nEpoch {epoch + 1} - Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Evaluation mode\n",
        "model.eval()\n",
        "correct = 0\n",
        "total_samples = 0\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "print(\"\\nEvaluating on the Test Set:\")\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "\n",
        "        # Track metrics\n",
        "        correct += (predictions == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "        all_predictions.extend(predictions.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Print final accuracy and detailed metrics\n",
        "test_accuracy = correct / total_samples\n",
        "print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_labels, all_predictions, target_names=label_mapping.keys()))\n",
        "\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yHtTYcpz6AW"
      },
      "source": [
        "## Part 3: Fine-Tuning TinyBERT with LoRA\n",
        "\n",
        "As you have experienced, training even a small-sized BERT model can be computationally intensive and time-consuming. To address these challenges, we explore **Parameter-Efficient Fine-Tuning (PEFT)** methods, which allow us to utilize the power of large pretrained models without requiring extensive resources.\n",
        "\n",
        "---\n",
        "\n",
        "### **Parameter-Efficient Fine-Tuning (PEFT)**\n",
        "\n",
        "PEFT methods focus on fine-tuning only a small portion of the model’s parameters while keeping most of the pretrained weights frozen. This drastically reduces the computational and storage requirements while leveraging the rich knowledge embedded in pretrained models.\n",
        "\n",
        "One popular PEFT method is LoRA (Low-Rank Adaptation).\n",
        "\n",
        "- **What is LoRA?**\n",
        "\n",
        "LoRA introduces a mechanism to fine-tune large language models by injecting small low-rank matrices into the model's architecture. Instead of updating all parameters during training, LoRA trains these small matrices while keeping the majority of the original parameters frozen.  This is achieved as follows:\n",
        "\n",
        "1. **Frozen Weights**: The pretrained weights of the model, represented as a weight matrix $ W \\in \\mathbb{R}^{d \\times k} $, remain **frozen** during fine-tuning.\n",
        "\n",
        "2. **Low-Rank Decomposition**:\n",
        "   Instead of directly updating $ W $, LoRA introduces two trainable matrices, $ A \\in \\mathbb{R}^{d \\times r} $ and $ B \\in \\mathbb{R}^{r \\times k} $, where $ r \\ll \\min(d, k) $.  \n",
        "   These matrices approximate the update to $ W $ as:\n",
        "   $$\n",
        "   \\Delta W = A \\cdot B\n",
        "   $$\n",
        "\n",
        "   Here, $ r $, the rank of the decomposition, is a key hyperparameter that determines the trade-off between computational cost and model capacity.\n",
        "\n",
        "3. **Adaptation**:\n",
        "   During training, instead of updating $ W $, the adapted weight is:\n",
        "   $$\n",
        "   W' = W + \\Delta W = W + A \\cdot B\n",
        "   $$\n",
        "   Only the low-rank matrices $ A $ and $ B $ are optimized, while $ W $ remains fixed.\n",
        "\n",
        "4. **Efficiency**:\n",
        "   Since $ r $ is much smaller than $ d $ and $ k $, the number of trainable parameters in $ A $ and $ B $ is significantly less than in $ W $. This makes the approach highly efficient both in terms of computation and memory.\n",
        "\n",
        "---\n",
        "\n",
        "###  **Fine-Tuning TinyBERT**\n",
        "\n",
        "For this part, we will fine-tune **TinyBERT**, a distilled version of BERT, using the LoRA method.\n",
        "\n",
        "- **What is TinyBERT?**\n",
        "\n",
        "TinyBERT is a lightweight version of the original BERT model created through knowledge distillation. It significantly reduces the model size and inference latency while preserving much of the original BERT’s effectiveness. Here are some key characteristics of TinyBERT:\n",
        "- It is designed to be more resource-efficient for tasks such as classification, question answering, and more.\n",
        "- TinyBERT retains a compact structure with fewer layers and parameters, making it ideal for fine-tuning with limited computational resources.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_Og-pBeV5x6"
      },
      "source": [
        "> Similar to the previous section, training this model might take some time. Given the resource limitations, you can train the model for just **2-3 epochs** to demonstrate the process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fe1vGCZwU7MZ"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIyN5vOLLWz6"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "model_name = \"prajjwal1/bert-tiny\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "base_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label_mapping))\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,  # Sequence Classification\n",
        "    r=8,                         # Rank of the low-rank matrices A and B\n",
        "    lora_alpha=32,               # Scaling factor\n",
        "    lora_dropout=0.1,            # Dropout regularization\n",
        "    target_modules=[\"query\", \"value\"]  # Only apply LoRA to attention layers\n",
        ")\n",
        "\n",
        "# Apply LoRA configuration to the base model\n",
        "lora_model = get_peft_model(base_model, lora_config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMgwZ8YmLuZ_"
      },
      "outputs": [],
      "source": [
        "lora_model = get_peft_model(base_model, lora_config)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "lora_model.to(device)\n",
        "\n",
        "trainable_params = sum(p.numel() for p in lora_model.parameters() if p.requires_grad)\n",
        "print(f\"Total Trainable Parameters: {trainable_params}\")\n",
        "\n",
        "optimizer = AdamW(lora_model.parameters(), lr=5e-5)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "num_epochs = 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total Trainable Parameters: 10643"
      ],
      "metadata": {
        "id": "1kJB4QJtMbQp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J395FrcWMbmx"
      },
      "outputs": [],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    lora_model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
        "    for batch in tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = lora_model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    accuracy = correct / total_samples\n",
        "    print(f\"Training Loss: {avg_loss:.4f}, Training Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "lora_model.eval()\n",
        "correct = 0\n",
        "total_samples = 0\n",
        "total_loss = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = lora_model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "test_loss = total_loss / len(test_loader)\n",
        "test_accuracy = correct / total_samples\n",
        "print(f\"\\nTest Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epoch 1/2\n",
        "100%|██████████| 11811/11811 [24:55<00:00,  7.90it/s]\n",
        "Training Loss: 1.4220, Training Accuracy: 0.4342\n",
        "\n",
        "Epoch 2/2\n",
        "100%|██████████| 11811/11811 [24:54<00:00,  7.90it/s]\n",
        "Training Loss: 1.2241, Training Accuracy: 0.5122\n",
        "\n",
        "100%|██████████| 2953/2953 [05:10<00:00,  9.50it/s]\n",
        "\n",
        "Test Loss: 1.1543, Test Accuracy: 0.5352\n"
      ],
      "metadata": {
        "id": "tAPhYf60Mo-M"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "020abce58cf143fe91fe7657c94ed57a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12266c1060fd41ce836408098d95b7a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f340eb5d8ca8401bbc349e49909dd9e1",
            "placeholder": "​",
            "style": "IPY_MODEL_9f58db67f6e54aa5a4201849524da0d1",
            "value": " 32332/32332 [00:00&lt;00:00, 189640.56 examples/s]"
          }
        },
        "191bcf61d97048df8fc80d2bf4239032": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7e35a425831469781d2801e5c0f0c46",
            "placeholder": "​",
            "style": "IPY_MODEL_37dcd52c6d4d435691ba1cdb99a900e8",
            "value": "README.md: 100%"
          }
        },
        "19a4bd1c26a64c73892883ecf845603f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19f1d87a8f2440e2a649fa1f1b31d2a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_191bcf61d97048df8fc80d2bf4239032",
              "IPY_MODEL_8a53a9f3ae67453b93d891fbf8d94006",
              "IPY_MODEL_4b606598fd4149d4abee122bd347314c"
            ],
            "layout": "IPY_MODEL_e23e6982ef2e424888839815130cb8a5"
          }
        },
        "2c4bd7bffdb94066981ff6fae0d5e36e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30f3c7ccb1ba4024becf1bd517233d25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33534b9cbbe244a289643b1fc1459806": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37dcd52c6d4d435691ba1cdb99a900e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3eb657598dd64d0c9c4eb4f8556c8348": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b606598fd4149d4abee122bd347314c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_558836b657ab49b9825b5aff2b697efe",
            "placeholder": "​",
            "style": "IPY_MODEL_3eb657598dd64d0c9c4eb4f8556c8348",
            "value": " 28.1k/28.1k [00:00&lt;00:00, 1.84MB/s]"
          }
        },
        "5449a611e4e54265bf5a0fb9389f39f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "558836b657ab49b9825b5aff2b697efe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62eecadd783d4c4ebc64320a6795e5ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ec149d09634422ea3c43ead572e6ab1",
              "IPY_MODEL_ba646af747784fe997c3ded6f4d8ae8e",
              "IPY_MODEL_12266c1060fd41ce836408098d95b7a8"
            ],
            "layout": "IPY_MODEL_8b2257ef94c449df84bf50e3e3dec13f"
          }
        },
        "6d277c340f09424a837f6938cd9c2b0f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73bfc0a51843402ab4b305501104106c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8046cc16e97d48fa86831841bb0364e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "83026d18a9284dfdb6f5f394afe4a295": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a53a9f3ae67453b93d891fbf8d94006": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33534b9cbbe244a289643b1fc1459806",
            "max": 28064,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8046cc16e97d48fa86831841bb0364e5",
            "value": 28064
          }
        },
        "8b2257ef94c449df84bf50e3e3dec13f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90c17936e09e485388b78c1fd6fd0353": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92ccba7af5f048808c30ebcc85ff9ad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90c17936e09e485388b78c1fd6fd0353",
            "placeholder": "​",
            "style": "IPY_MODEL_83026d18a9284dfdb6f5f394afe4a295",
            "value": " 5.73M/5.73M [00:00&lt;00:00, 20.2MB/s]"
          }
        },
        "9ec149d09634422ea3c43ead572e6ab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f405fd82b5634a4ea0b2207227e6cf7f",
            "placeholder": "​",
            "style": "IPY_MODEL_2c4bd7bffdb94066981ff6fae0d5e36e",
            "value": "Generating train split: 100%"
          }
        },
        "9f58db67f6e54aa5a4201849524da0d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7b7b53b11ff4da5963fdb9f7c9c96da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d277c340f09424a837f6938cd9c2b0f",
            "max": 5726189,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30f3c7ccb1ba4024becf1bd517233d25",
            "value": 5726189
          }
        },
        "a7e35a425831469781d2801e5c0f0c46": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad896f0e5dea477c92553f959baa5d87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba646af747784fe997c3ded6f4d8ae8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5449a611e4e54265bf5a0fb9389f39f9",
            "max": 32332,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73bfc0a51843402ab4b305501104106c",
            "value": 32332
          }
        },
        "e23e6982ef2e424888839815130cb8a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e623e0ad546f431a8a8e9976c3edd3e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19a4bd1c26a64c73892883ecf845603f",
            "placeholder": "​",
            "style": "IPY_MODEL_ad896f0e5dea477c92553f959baa5d87",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "f340eb5d8ca8401bbc349e49909dd9e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f405fd82b5634a4ea0b2207227e6cf7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd8308f41d3e4a7793b5d5910a6dd2cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e623e0ad546f431a8a8e9976c3edd3e7",
              "IPY_MODEL_a7b7b53b11ff4da5963fdb9f7c9c96da",
              "IPY_MODEL_92ccba7af5f048808c30ebcc85ff9ad3"
            ],
            "layout": "IPY_MODEL_020abce58cf143fe91fe7657c94ed57a"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}